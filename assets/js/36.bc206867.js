(window.webpackJsonp=window.webpackJsonp||[]).push([[36],{407:function(e,t,a){"use strict";a.r(t);var n=a(2),s=Object(n.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h2",{attrs:{id:"什么是flume"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#什么是flume"}},[e._v("#")]),e._v(" 什么是Flume?")]),e._v(" "),t("blockquote",[t("p",[e._v("flume 可以理解为一个分布式的日志采集系统，是Hadoop的组件之一，可以收集例如日志，事件等数据资源，并将这些数量庞大的数据从各项数据源中集中起来存储的工具/服务。\n不仅如此，它还可以采集文件，socket数据包（网络端口）、文件夹、kafka、mysql数据库等各种形式源数据，并将采集到的数据(下沉sink)输出到HDFS、hbase、hive、kafka等众多外部存储系统中。")])]),e._v(" "),t("h2",{attrs:{id:"flume特性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#flume特性"}},[e._v("#")]),e._v(" Flume特性")]),e._v(" "),t("ol",[t("li",[e._v("高可用、可靠：Flume是一个分布式、可靠、和高可用的海量日志采集、汇聚和传输的系统")]),e._v(" "),t("li",[e._v("具备良好的自定义扩展能力：Flume针对特殊场景也具备良好的自定义扩展能力，因此，flume可以适用于大部分的日常数据采集场景")])]),e._v(" "),t("h2",{attrs:{id:"flume使用场景"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#flume使用场景"}},[e._v("#")]),e._v(" Flume使用场景")]),e._v(" "),t("ol",[t("li",[e._v("海量日志采集")]),e._v(" "),t("li",[e._v("文件、socket数据包（网络端口）、文件夹、kafka、mysql数据库等各种形式源数据采集")])]),e._v(" "),t("h2",{attrs:{id:"flume组成"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#flume组成"}},[e._v("#")]),e._v(" Flume组成")]),e._v(" "),t("h3",{attrs:{id:"_1-agent"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-agent"}},[e._v("#")]),e._v(" 1.agent")]),e._v(" "),t("blockquote",[t("p",[e._v("Flume中最核心的角色是agent，flume采集系统就是由一个个agent连接起来所形成的一个或简单或复杂的数据传输通道。\n对于每一个Agent来说,它就是一个独立的守护进程(JVM),它负责从数据源接收数据，并发往下一个目的地")])]),e._v(" "),t("p",{attrs:{align:"center"}},[t("img",{staticStyle:{cursor:"zoom-in"},attrs:{src:"/images/flume/01.jpg"}})]),e._v(" "),t("blockquote",[t("p",[e._v("每一个agent相当于一个数据(被封装成Event对象)传递员，内部有3个核心组件：")])]),e._v(" "),t("ol",[t("li",[e._v("Source：采集组件，用于跟数据源对接，以获取数据；它有各种各样的内置实现；")]),e._v(" "),t("li",[e._v("Sink：下沉组件，用于往下一级agent传递数据或者向最终存储系统传递数据")]),e._v(" "),t("li",[e._v("Channel：传输通道组件，用于从source将数据传递到sink")])]),e._v(" "),t("h3",{attrs:{id:"_2-event"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-event"}},[e._v("#")]),e._v(" 2.Event")]),e._v(" "),t("blockquote",[t("p",[e._v("数据在channel中的封装形式，因此Source组件在获取到原始数据后，需要封装成Event放入channel，\nSink组件从channel中取出Event后，需要根据目标存储的需求，转成其他形式的数据输出。\nEvent封装对象主要有两部分组成： Headers和  Body")])]),e._v(" "),t("ol",[t("li",[e._v("header是一个集合  Map[String,String]，用于携带一些KV形式的元数据（标志、描述等）")]),e._v(" "),t("li",[e._v("body： 就是一个字节数组byte[]；装载具体的数据内容")])]),e._v(" "),t("h3",{attrs:{id:"_3-channel-selector"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-channel-selector"}},[e._v("#")]),e._v(" 3.channel selector")]),e._v(" "),t("blockquote",[t("p",[e._v("一个source可以对接多个channel，则event在这n个channel之间传递的策略，由配置的channel selector决定；\nchannel selector有2中实现： replicating（复制），multiplexing（多路复用）")])]),e._v(" "),t("h3",{attrs:{id:"_4-sink-processor"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-sink-processor"}},[e._v("#")]),e._v(" 4.sink processor")]),e._v(" "),t("blockquote",[t("p",[e._v("如果sink和channel是一对一关系，则不需要专门的sink processor；\n如果要配置一个channel对多个sink，则需要将这多个sink配置成一个sink group（sink组）；\nevent在一个组中的多个sink间如何传递，则由所配置的sink processor来决定；\nsink processor有2种： load balance (round robing)和 fail over")])]),e._v(" "),t("h3",{attrs:{id:"_5-interceptor拦截器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-interceptor拦截器"}},[e._v("#")]),e._v(" 5.interceptor拦截器")]),e._v(" "),t("blockquote",[t("p",[e._v("拦截器工作在source组件之后，source产生的event会被传入拦截器根据需要进行拦截处理，而且，拦截器可以组成拦截器链！\n拦截器在flume中有一些内置的功能比较常用的拦截器，用户也可以根据自己的数据处理需求，自己开发自定义拦截器！\n这也是flume的一个可以用来自定义扩展的接口！")])]),e._v(" "),t("h3",{attrs:{id:"_6-transaction-事务控制机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_6-transaction-事务控制机制"}},[e._v("#")]),e._v(" 6.Transaction：事务控制机制")]),e._v(" "),t("blockquote",[t("p",[e._v("Flume使用两个独立的事务：")])]),e._v(" "),t("ol",[t("li",[e._v("put操作：source读取数据源并写入event到channel")]),e._v(" "),t("li",[e._v("take操作：sink从channel中获取event并写出到目标存储")])]),e._v(" "),t("blockquote",[t("p",[e._v("事务的实现程度，取决于运行时所选择的具体的组件实现类；再好的组件的组合，也只实现到了at least once!（不会丢失数据，但可能产生重复传输）\n事务实现的核心点，就是记录状态（比如source，记录自己完成的数据的偏移量），比如spooling directory source 为文件的每一个event batch\n创建一个事务，来记录状态，一旦事务中所有的事件全部传递到channel且提交成功，那么soucrce就将event batch标记为完成。\n同理，事务以类似的方式处理从channel到sink的传递过程，如果因为某种原因使得事件无法记录，那么事务将会回滚，且所有的事件都会保持到channel中，等待重新传递。")])]),e._v(" "),t("h2",{attrs:{id:"参考链接"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#参考链接"}},[e._v("#")]),e._v(" 参考链接")]),e._v(" "),t("ol",[t("li",[e._v("https://blog.csdn.net/qq_30612351/article/details/109575886")])])])}),[],!1,null,null,null);t.default=s.exports}}]);